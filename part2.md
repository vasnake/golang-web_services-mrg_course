# Разработка веб-сервисов на Golang (Go). Часть 2

[Go course, MRG, Романов Василий](README.md)
[Разработка веб-сервисов на Golang (Go), Василий Романов, stepik](https://stepik.org/187490)

Неделя 5 - продолжаем работу с HTTP, Анатомия веб-сервиса
- 5.1 Приветствие 
- 5.2 Middleware 
- 5.3 Роутинг http-запросов 
- 5.4 Валидация входящих данных 
- 5.5 Фреймворки 
- 5.6 Логирование 
- 5.7 Веб-сокеты 
- 5.8 Шаблонизация 
- 5.9 Задание 5 - веб-фреймворк на основе кодогенерации

Неделя 6 - базы данных, SQL NoSQL
- 6.1 SQL 
- 6.2 KV-хранилища 
- 6.3 Rabbit, Mongodb 
- 6.4 Задание 6 - универсальный сервис просмотра содержимого БД

Неделя 7 - основы микросервисов, Микросервисы
- 7.1 Что такое микросервис 
- 7.2 Делаем микросервис руками 
- 7.3 protobuf и gRPC 
- 7.4 Дополнительные темы 
- 7.5 Задание 7 - асинхронная система логирования

Неделя 8 - прочие темы, Сервис в работе
- 8.1 Конфигурирование сервиса 
- 8.2 Мониторинг 
- 8.3 Низкоуровневое программирование 
- 8.4 Инструменты для статического анализа 
- 8.5 Задание 8 - заполнение полей структуры через рефлексию

- [Код, домашки, литература](week_05/materials.zip)
- [UPD: Код, домашки, литература](./handouts\golang_web_services_2023-12-28.zip)

## part 2, week 1 (05)

Анатомия веб-сервиса

```s
pushd sandbox
mkdir -p week05 && pushd ./week05
go mod init week05

cat > main.go << EOT
package main
func main() { panic("not yet") }
EOT

go mod tidy
popd

go work use ./week05
go vet week05
gofmt -w week05
go run week05
go test -v week05
```
[week 5 playground](./sandbox/week05/main.go) `GO_APP_SELECTOR=week05 gr`

### Приветствие 1

Привет, будем галопом по веб-сервисам. Обзорно. Рассмотрим: какие задачи встречаются при разработке веб-сервисов.
Лучшие практики по решению этих задач остаются за кадром.

### Приветствие 2

Анатомия, (готовые?) компоненты веб-сервиса, которые так-или-иначе существуют в разных фреймворках:
- роутинг: отображение урлов (запросов) на функции
- авторизация/аутентификация/идентификация, управление сессиями
- балансировка нагрузки, распределение запросов/сессий по разным воркерам (про это лектор не сказал ничего)
- логирование (трассировка туда же), сбор инфы для анализа офлайн
- обработка ошибок (соответствие протоколу, сбор инфы для анализа офлайн)
- валидация входных параметров запросов
- шаблонизация (рендеринг респонса)
- конфигурировние (конфиг как код, централизованное управление, безопасная доставка секретов, ...), изменение параметров без перезагрузки
- мониторинг (сбор метрик для онлайн/офлайн анализа)
- миддлваре/фреймворки (слои обработчиков запросов, пайплайн обработки как цепочка миддлварей + бизнес-логика)
- работа с IO device (SQL, NoSQL БД, xz-хранилища, очереди, etc.)

В курсе рассмотрены компоненты, реализация которых доступна "из коробки".

### Middleware 1 (wrappers)

- [middleware](week_05/middleware.go)

- Как мог бы выглядеть код миддлваре, если бы мы всё писали руками:
обработка паники, запись в лог, проверка авторизации; и после всего этого уже бизнес-логика.

Можно лучше: заворачивание хендлеров в "декораторы" middleware.
Middleware в данном случае это фунция handler => handler. Или ServerMux => ServerMux.
Выглядит как композиция функций, получение матрешки обработчиков пары (ответ, запрос).

Демонстрация сервера, который реализует вот это все в мидлварях.

Первый выполняется миддлв. накрученный последним: FILO.

В голову приходит термин: Аспект-ориентированое программирование.

### Middleware 2 (metrics using context)

- [context_value](week_05/context_value.go)

Демо:
используем Context запроса `http.Request.Context()` для реализации мидлвари, в которой вычисляются тайминги.
Ценный пример мониторинга времени, уходящего на обработку запроса в целом и его частей.

`req.Context()` как хранилище данных.
Контекст запроса живет пока живет запрос.
Хранилище значений в контексте не типизированное, не надо его использовать если можно обойтись без этого.

Каждый вызов бизнес-логики завернут в декоратор, который, с использованием контекста, вычисляет время, затраченное операцией.
Потом миддлварь отсылает собранные в контексте данные в мониторинг, лог, etc.

Перед выполением запроса контекст инициализируется, создается структура (на базе мапки) в которую будут собираться данные.
На выход навешивается defer, в котором подбиваются итоги.
И вызывается бизнес-логика, в которой контекст будет обновляться при сборе данных мониторинга.

Значения в контексте не типизированные, компайл-тайм проверок нет. Поэтому -- очень осторожно и только если по другому нельзя!

Пустой интерфейс -- зло, реализовывать протоколы через них не надо, проверять и отлаживать очень сложно.
Как вариант -- сделайте свой контекст, с конкретными типами.

### Middleware 3 (errors)

- [basic_err](week_05/basic_err.go)
- [named_err](week_05/named_err.go)
- [own_err](week_05/own_err.go)
- [pkg_err](week_05/pkg_err.go)

Как лучше обрабатывать ошибки (в хендлерах запросов):
собрать и вывести информации побольше; трансформировать ошибку в ошибку с подробностями:
обмазать перехваченную ошибку детализацией, позволяющей потом провести анализ и найти источник проблем.

Еще лучше: типизированная ошибка. С помощью `errors.New()` создаются константы-ошибки для использования в коде (`switch err`).

Или еще лучше: создается новый тип данных, структура с расширенным описанием ошибки, для использования в качестве возвращаемого значения.
Достаточно реализовать интерфейс `Error() string` и можно пользоваться структурой как стандартной ошибкой (`switch err.(type)`).

Универсальный (рекомендуемый) враппер ошибок сделан в `github...pkg/errors`. `errors.Wrap(...)`, `errors.Cause(err).(type)`, ...
А еще там есть вывод stacktrace.

### Роутеры 1 (gorilla, httprouter)

- [gorilla](week_05/gorilla.go)
- [httprouter](week_05/httprouter.go)
- [multiple](week_05/multiple.go)

`gorilla/mux`, мощный роутер, позволяет задать метод HTTP (POST, GET, ...), 
задать сложные правила матчинга не только по урл но и по другим параметрам запроса, многое другое.
Один из самых медленных роутеров.

`HttpRouter`, вполне годная производительность (prefix-tree). 
Не такой мощный как горилла; сигнатура хендлеров не совместима с оригинальными гошными хендлерами.

Можно испльзовать разные роутеры в разных частях сервиса, на разные эндпойнты повесить разные хендлеры от разных роутеров.
При запуске сервера эти хендлеры все пихаются в один мультиплексор.
Пример с использованием трех роутеров в одном сервисе.
Tradeoff: speed/power

https://github.com/julienschmidt/go-http-routing-benchmark

### Роутеры 2 (fasthttp)

- [fasthttp](week_05/fasthttp.go)

`fasthttp` быстрый веб-сервер для Go.
Уж если задумались о быстрых роутерах, почему бы не оптимизировать веб-сервер.
Использовать с `fasthttprouter`.
Совсем другая сигнатура хендлеров.
Мутабельные структуры, вывод происходит после установки всех параметров.
С горутинами будет сложно, ибо мутабельность.

От себя могу добавить: не завязывайте много логики на особенности фреймворков и библиотек.
Если в архитектуре аппы есть слой легковесных адаптеров, за которыми прячется конкретный API фреймворка, то заменить один
фреймворк на другой будет несложно.

### Валидация

- [validation](week_05/validation.go) валидация параметров запроса

Нет стандартного способа валидации, всё проекто-зависимо.
Есть пакеты `asaskevich/govalidator`, `gorilla/schema`, другие.
Первый: только валидатор. Второй: парсинг + валидация.
Это работает на рефлексии. Если надо, чтобы валидация работала быстрее, делайте кодогенератор или пишите руками.

Me:
Если надо шлепать на конвейере, то нужно что-то декларативное.
Если одиночные проекты, то можно и руками парсинг-валидацию написать.

### web-site Фреймворки 1 (Beego)

https://beego.me/ фреймворк https://github.com/beego/beego

`bee new web_bp; cd web_bp; bee run`
`bee api user; cd user; bee run -gendoc=true -downdoc=true`

Можно сгенерировать html web сайт; можно сгенерировать сайт с json (REST) API, c документацией Swagger.
Много компонент, для быстрого старта очень неплохо.
Похоже на Django.

### web-site Фреймворки 2 (gin)

- [main](week_05/main.go), UPD: `handouts\golang_web_services_2023-12-28.zip\5\frameworks\gin\main.go`

`gin-gonic/gin` фреймворк https://github.com/gin-gonic/gin

Быстрый и функциональный, простой.
Генераторов (как в Beego) нет.
Ближе к Flask.

### Логирование

- [logging_main](week_05/logging_main.go), UPD: `handouts\golang_web_services_2023-12-28.zip\5\logging\main.go`

Несколько подходов к логированию, Demo: через мидлварь выводит в лог 5 строк разными способами.

Стандартный логгер `log`;
`zap` - структурированные логи;
`logrus` - делает вид, что структурированный.

`logrus` имеет много коннекторов, для отсылки логов в разные приемники https://github.com/sirupsen/logrus/wiki/Hooks. Медленный.

`zap` на порядок быстрее https://github.com/uber-go/zap?tab=readme-ov-file#performance

Структурированный лог позволяет устранить рефлексию и аллокацию памяти, благодаря явному указанию структуры сообщения (типов значений).

UPD: говорят, в Го завезли недавно структурированные логи.

### Веб-сокеты

- [websockets_main](week_05/websockets_main.go) [websockets_index.html](week_05/websockets_index.html)
UPD: 
- `handouts\golang_web_services_2023-12-28.zip\5\websockets\index.html`
- `handouts\golang_web_services_2023-12-28.zip\5\websockets\main.go`

`gorilla/websockets`, страница с яваскрипт, открывает асинхронный канал на вебсокете.

Вебсокеты: дуплексный канал страница-JS-сервер. Push, Pull, все дела. В основном для легковесного Push.
В Го из коробки нет вебсокетов, нужны сторонние пакеты.

- https://github.com/nhooyr/websocket
- https://github.com/gorilla/websocket

### Шаблонизация

Demo: кодогенерация шаблона в модуль Го, использование модуля для рендеринга страницы
- [template_main](week_05/template_main.go) `handouts\golang_web_services_2023-12-28.zip\5\template_adv\main.go`
- [template_index.html](week_05/template_index.html) `handouts\golang_web_services_2023-12-28.zip\5\template_adv\template\index.html`

Стандартный шаблонизатор медленный, на рефлексии.

Шаблонизатор `Hero` https://github.com/shiyanhui/hero, прекомпиляция шаблонов в код Go.
Шаблон содержит (не текстовые вставки в коде а наоборот) вставки кода Го в текст страницы.

В исходном коде аппы можно оставить спец.комментарий:
`go:generate hero -source=./template/` -- комментарий-маркер для команды `go generate`.

Недостаток: шаблон по горячему не перезапустишь. Надо пересобирать программу.
Преимущество: очень быстро выводит страницы.

При выводе шаблона используется буфер (выделение/освобождение памяти), надо использовать pool для переиспользования ресурсов.

https://github.com/slinso/goTemplateBenchmark

### Управление зависимостями (deprecated)

UPD: Все зависимости через систему модулей https://go.dev/doc/modules/managing-dependencies

- [dependencies_main](week_05/dependencies_main.go)

`go get ...` неудобно, нет автоматики. Нужен менеджер (dep, glide, gb).

`dep init` регистрирует зависимости проекта со всеми версиями.
`vendor` directory с кодом зависимостей.
Все зависимости надо качать себе. Всё равно всё собирается в статический бинарник.

```s
# https://github.com/golang/dep
dep init
dep ensure
dep ensure -add github.com/foo/bar
dep status
dep ensure -update
```

### week5 homework

Фолдер с задачей: `handouts\golang_web_services_2023-12-28.zip\5\99_hw\codegen\`

Описание задачи: `readme.md`

Написать программу кодогена `handlers_gen\codegen.go`
> Запуск (кодогена) будет выглядеть примерно так: `go build handlers_gen/* && ./codegen api.go api_handlers.go`
Т.е. запускаться он будет как `бинарник_кодогенератора что_парсим.го куда_парсим.го`

- `api.go` - этот файл вам надо скармливать в кодогенератор. редактировать его не надо
- `main.go` - редактировать не надо (нужно только для "поиграть в браузере")
- `main_test.go` - этот файл надо запускать для тестирования после кодогенерации. редактировать не надо

> Запуск тестов будет происходить так:
`go build handlers_gen/* && ./codegen.exe api.go api_handlers.go && go test -v`

[actual homework project](./sandbox/week05_homework/codegen/) `GO_APP_SELECTOR=week05_homework gr`
```s
pushd sandbox # workspace
mkdir -p week05_homework/codegen/handlers_gen
pushd week05_homework/codegen

go mod init codegen

# makes go vet happy
cat > main.go << EOT
package main
func main() { panic("not yet") }
EOT

cat > handlers_gen/codegen.go << EOT
package main
func main() { panic("not yet") }
EOT

go mod tidy

popd # workspace
# go work init
# go work edit -dropuse=./week05_homework/code_gen
go work use ./week05_homework/codegen

go vet codegen
gofmt -w ./week05_homework/codegen
go test -v codegen
```
codegen prj.

Своими словами: есть (условно) реализация некоторого внутреннего API, для нее надо создать адаптеры,
для работы с апи-шкой через интерфейс http. С обеих сторон протокол определен, код адаптеров можно создавать
кодогенерацией. Что позволит получить малые потери в производительности, при правильном построении шаблонов кодогенератора.
- Первым делом я руками реализовал логику адаптеров. Первая версия получилась понятная, но не самая производительная.
- Сделал руками вторую версию адаптеров, затооченную на производительность.
- Реализовал кодогенератор, на базе предоставленного примера.

## part 2, week 2 (06)

SQL, NoSQL
[Код, домашки, литература](week_06/materials.zip)
UPD:
- `handouts/golang_web_services_2023-12-28.zip/6/`
- `handouts/golang_web_services_2024-04-26.zip/6/`

```s
pushd sandbox
mkdir -p week06 && pushd ./week06
go mod init week06

cat > main.go << EOT
package main
func main() { panic("not yet") }
EOT

go mod tidy
popd

go work use ./week06
go vet week06
gofmt -w week06
go run week06
go test -v week06
```
[week 6 playground](./sandbox/week06/main.go) `GO_APP_SELECTOR=week06 gr`

Для запуска демо программ: необходимо поднять контейнеры `docker compose up`.

### SQL 1 (manual)

- [items.sql](week_06/items.sql) [main.go](week_06/main.go)

Демо простой веб-страницы (без валидаций, обработки ошибок, защиты) с операциями CRUD для сущностей типа "Post".
Записи блога или типа того.
Подключение к БД, навешивание хендлеров на роуты, запуск веб-сервера.
Хендлеры -- методы структуры, в которую мы положили коннект к БД и шаблоны страниц.

Есть (в Go) интерфейс `database/sql`,
Этот интерфейс реализован в `go-sql-driver/mysql`,
который внутре себя биндится на стандартный интерфейс (вся магия в методе `init`) и ничего не экспортирует.
В коде используется стандартный `database/sql`.

`sql.NullString` vs `string`: не смог объяснить, чем одно лучше другого.
Подозреваю, тем, что пустая строка и null должны как-то отличаться, поэтому нужен тип строки с дискриминацией null.

Ну, как бы, руками перекладывать данные в/из sql запросы неудобно.

### SQL 2 (gorm)

- [gorm_main](week_06/gorm_main.go) та же аппликуха, на той же БД, только для походов в БД используем либу gorm.

А нельзя ли все кишки (типа разбора параметров, генерации запросов, выполнения и проверки результата) завернуть в универсальную оболочку?
Можно (ORM). Работать будет либо через рефлексию, либо через кодогенерацию.
Посмотрим на `gorm`: `db, err := gorm.Open("mysql", dsn)`.
Работает через рефлексию, удобно, вполне можно пользоваться для простых вещей.

Структура таблицы снабжена тегами (хинты горму) и методами (хуки и переопределения для горм).
В целом: удобно, но теряется гибкость и производительность.

### SQL 3 (sql injection)

- [sql_injection_main](week_06/sql_injection_main.go)

Используйте плейсхолдеры, не подставляйте параметры руками.
Демо логина с админскими привилениями через нехитрый трюк модификации sql запроса.

### Key-Value 1 (тегированнй кеш, memcache)

- [memcache](week_06/memcache.go)
- [main](week_06/tcache_main.go)
- [cache](week_06/tcache_cache.go)

Package `gomemcache/memcache`.

Тегированный кеш: к записям (в домене некоторой логики) добавлена метаинформация в виде
тег:счетчик. Когда такая запись кладется в кеш, сохраняются "версии" тегов.
Текущее значение версии тега лежит там же, в кеше, инкрементируется атомарно при обновлении данных.
Счетчик увеличивается при обновлении (метка времени как счетчик?).
При считывании данных из кеша, проверим: 
мы сравниваем значения под нашим тегом с образцом (текущим значением).
По результатам сравнения принимаем решение: что делать с кешированной записью (отбросить и получить свежак из оригинала).
Т.е. если версия в кеше меньше версии текущей, то кеш устарел.

Разбор (учебного) универсального решения на тегированном кеше (подробности в коде).
Довольно много низкоуровневой возни с TTL, блокировками, коллбеками и маршаллингом значений.

### Key-Value 2 (redis)

- [main](week_06/redis_main.go)
- [session](week_06/redis_session.go)

Использование `redigo/redis` для хранения сессий пользователей веб-сайта.
id сессии лежит в куке, данные сессии лежат в redis.

Учебный пример для демонстрации основных операций над бд, для работы с сессией через редис.

https://redis.io/docs/latest/commands/

### Прочие системы 1 (Rabbit MQ)

- [form](week_06/rabbit_form.go)
- [pic resize_worker](week_06/rabbit_resize_worker.go)

Обмен сообщениями, очереди, Pub/Sub, RabbitMQ "github.com/streadway/amqp".

Демо веб-сервиса создания превьюшек для картинок. Превьюшки создаются в async офлайн воркере.
Пользователь грузит картинку на сервер через веб-форму.
Задание на обработку файла идет в очередь, пользователь получает отбивку о запуске фонового процесса.
По завершению обработки: пользователь получит сообщение о готовности.
Обмен сообщениями (реализация протокола): через очереди. Так должно быть.
Как работает демо: пользователь отправляет файл (веб-форма) на сервер.
Там файл сохраняется на диск, в очередь кладется реф.на файл и задание "генерить превьюшки".
Пользователь получает ответ, что файл принят в обработку.
Фоновый воркер (отдельный процесс) берет задания из очереди и строгает превьюшки,
складывая их на диск. TheEnd.

Показал хитрость, как в один проход чтения файла посчитать хеш и переложить байты из формы.

```s
pushd sandbox/week06
mkdir -p rabbit_pic_resize_worker && pushd ./rabbit_pic_resize_worker
go mod init rabbit_pic_resize_worker

cat > worker.go << EOT
package main
func main() { panic("not yet") }
EOT

go mod tidy
popd # week06

go run rabbit_pic_resize_worker/worker.go&
```
Программа-воркер, ничего не знает про веб-сервис, просто берет задания из очереди и выполняет их.
Использует модуль `go get github.com/nfnt/resize`

Напоминалка: запуск этой демы в три шага:
```s
sandbox/week06$ mkdir -p images
sandbox/week06$ go run rabbit_pic_resize_worker/worker.go&
sandbox/week06$ go run week06
```
wsl snippets

### Прочие системы 2 (MongoDB)

- [main](week_06/mongodb_main.go)

Хранилище документов в монго `mgo "gopkg.in/mgo.v2"`, демо:
коллекция "публикаций", операции CRUD.
Пропедалировал то, что схемы как таковой нет, в запросы к монго можно посылать произвольные сообщения (бинарный джейсон),
где требуется только object id.

Проблема: коннект аппы к монге не устанавливается. Причина непонятна.

### week6 homework

# I_AM_HERE

Фолдер с задачей: `handouts/golang_web_services_2023-12-28.zip/6/99_hw/db_explorer/`

Описание задачи: `readme.md`

> простой веб-сервис будет представлять собой менеджер MySQL-базы данных,
который позволяет осуществлять CRUD-запросы к ней по HTTP

Задача выполнена когда: выполняются тесты `go test -v -race`, в браузере можно управлять табличками.

> Для пользователя это выглядит так (GET, PUT, POST, DELETE - это http-метод, которым был отправлен запрос):
* `GET /` - возвращает список всех таблиц (которые мы можем использовать в дальнейших запросах)
* `GET /$table?limit=5&offset=7` - возвращает список из 5 записей (limit) начиная с 7-й (offset) из таблицы $table.
limit по-умолчанию 5, offset 0
* `GET /$table/$id` - возвращает информацию о самой записи или 404
* `PUT /$table` - создаёт новую запись, данный по записи в теле запроса (POST-параметры)
* `POST /$table/$id` - обновляет запись, данные приходят в теле запроса (POST-параметры)
* `DELETE /$table/$id` - удаляет запись

- `db_explorer.go` здесь надо написать реализацию веб-сервиса, остальные файлы можно не трогать.
- `docker-compose.yaml`: для запуска сервера бд `docker compose up`
- `main.go`: для запуска веб-сервиса, чтобы в браузере поиграть
- `main_test.go`: тесты веб-сервиса `go test -v -race`

[actual homework project](./sandbox/week06_homework/db_explorer/) `GO_APP_SELECTOR=week06_homework gr`
```s
pushd sandbox # workspace
mkdir -p week06_homework/db_explorer
pushd week06_homework/db_explorer

go mod init db_explorer

# makes go vet happy
cat > main.go << EOT
package main
func main() { panic("not yet") }
EOT

go mod tidy

popd # workspace
# go work init
# go work edit -dropuse=./week05_homework/code_gen
go work use ./week06_homework/db_explorer
```
db_explorer prj.

## part 2, week 3 (07)

Микросервисы
[Код, домашки, литература](week_07/materials.zip) https://cloud.mail.ru/public/GyVL/2YfhX2unF

### Что такое микросервис - 1 (вводная)

Упрощение и борьба со сложностью.
Монолит vs микросервисы.
Монолит: сложно поддерживать, менять, развивать, деплоить, масштабировать.
Микросервисы: накладные расходы на коммуникацию, ошибка в разработке (архитектуре) протоколов приводит к пиздецу.

Первый шаг -- изолировать компоненты "сервиса" за интерфейсами.
Второй шаг -- вынести компоненты в отдельную программу, реализовав коммуникацию через, к примеру, RPC.

### Что такое микросервис - 2 (рефакторинг с целью изоляции)

before
- [lite](week_07/service_lite_before.go)
- [session](week_07/service_session_before.go)

after
before
- [lite](week_07/service_lite_after.go)
- [session](week_07/service_session_after.go)

Демо: веб-страница, логин-пароль, сессия.
Три функции: создать сессию, проверить сессию, удалить сессию.
Используют глобальные переменные: хранилище сессий и мютекс.

Чтобы высадить эту функциональность в изолированный модуль, надо код немного переписать.
Для начала избавиться от глобальных переменных, убрав их в структуру, экземпляр которой будет передаваться как параметр.
Фунции становятся методами этой структуры.

Чтобы иметь возможность играть с реализацией, над структурой-с-методами лепим интерфейс, реализацией которого эта структура и занимается.
Везде, где используются те функции, их вызов меняется на использование интерфейса.

### Делаем микросервис руками - 1 (вынос изолированного модуля в микросервис)

- [server](week_07/het_rpc_server.go)
- [session](week_07/het_rpc_session.go)
- [client_session](week_07/het_rpc_client_session.go)
- [client](week_07/het_rpc_client.go)

Ранее модуль сессии был изолирован. Теперь его можно вынести в микросервис.
Используем `net/rpc`, `net/http` для коммуникации.
Для прода В.Романов не рекомендует его использовать: сериализация чисто гошная, нет "авторизации", ...
Хотя пользовательский интерфейс остался прежним, внутри реализация сессий слегка поменялась:
пришлось переделать сигнатуры методов, дергаемых через RPC, ибо пакет `net/rpc` требует два параметра на входе (вход, буфер_результата) и ошибку на выходе.

В итоге имеем сервер, реализацию логики сессий (используется сервером), клиентскую обёртку на сервисом -- адаптер.
И клиента, которой через адаптер дергает сервер, который выполняет логику.

### Делаем микросервис руками - 2 (jsonrpc server)

- [server](week_07/jsonrpc_server.go)

Сериализация (протокол коммуникации) через JSON, `jsonrpc`.
Гораздо удобнее.
Есть кодек для `net/rpc`.
Пример с сервисом сессий на `jsonrpc`: `err := h.rpcServer.ServeRequest(serverCodec)`.

### protobuf and gRPC - 1 (что такое protobuf)

- [main](week_07/protobuf_main.go)
- [session.proto](week_07/protobuf_session.proto)

Форматы сериализации.
`JSON` -- формат без схемы, тяжело декодировать но легко читать и лепить изменения. Пересылать надо много байт.

`protobuf` -- кодогенерация, жёстко задана схема, экономный, бинарный: (номер поля и тип, длина данных, данные).
По файлу схемы генерится код для любой платформы `protoc --go_out=. *.proto`.
Поля нумеруются, поэтому можно добавлять ранее не задействованные номера => расширяемая схема.
Используется в gRPC.
`golang/protobuf/proto`

### protobuf and gRPC - 2 (grpc framework)

- [session.proto](week_07/grpc_session.proto)
- [session.go](week_07/grpc_session.go)
- [server](week_07/grpc_server.go)
- [lite](week_07/grpc_lite.go)

https://grpc.io/ - фреймворк использующий protobuf. Рекомендован к использованию в прод.

В файле proto появилось описание сервиса `service AuthChecker {...}`.
При кодогенерации нужен плагин: `protoc --go_out=plugins=grpc:. *.proto`.
После генерации мы получаем файл, в котором определены сообщения и интерфейсы для клиента и сервера.
Наряду с кодом, выполняющим коммуникацию.

Для серверной части остается написать реализацию интерфейса. И завернуть это в `grpc.NewServer()` для запуска сервера.

Клиенту надо сделать чуть больше приседаний, чем серверу, чтобы установить соединение.
При вызове grpc функций, первым параметром идёт некий "контекст". В контексте можно управлять разными опциями.

### protobuf and gRPC - 3 (возможности grpc)

- [client](week_07/grpc2_client.go)
- [server](week_07/grpc2_server.go)
- [session](week_07/grpc2_session.go)

Что насчет авторизации, логов, ...?
Есть опции: мидлварь ...Interceptor; метаданные в сообщении ...Credentials, ...
`grpc.WithUnaryInterceptor...grpc.WithPerRPCCredentials...`
Мидлварь позволяет декорировать RPC нужным образом (see aspect-oriented-programming).

Метаданные можно передать при создании соединения, один раз, с использованием `WithPerRPCCredentials`.
Можно передавать в контексте при каждом вызове.
Можно получать метаданные из выполненного вызова `var header, trailer metadata.MD`, через контекст.

На сервере тоже есть возможность использовать декораторы `...Interceptor` и метаданные запроса в контексте.

`grpc.InTapHandle` как инструмент ratelimit. Срабатывает на попытке соединиться, параметры запроса еще не распакованы.

Не надо использовать метаданные как параллельное API. Используйте для накручивания инструментов типа мониторинга, доступа, управления каналом, etc.

### protobuf and gRPC - 4 (streaming)

- [translit.proto](week_07/grpc_stream_translit.proto)
- [translit.go](week_07/grpc_stream_translit.go)
- [client.go](week_07/grpc_stream_client.go)

Особенность grpc -- стриминг. Отправка-прием данных в одном канале, частями.

Посмотрим на придуманный сервис транслитерации ...
У сервиса параметры `... stream Word => stream Word ...`.
Поток слов.

Для отправки и приема сообщений через поток, используются методы `Send`, `Recv`.

В реализации, входной поток служит одновременно и выходным. Мы как считываем из него слово, так и пишем в него ответ, пока не встретим `io.EOF`.

Никто не мешает читать и писать в разных горутинах, асинхронно. Понадобится очередь, для поддержки порядка и буферизации.

Клиент пишет и читает в двух горутинах, используя цикл для итерации по стриму.

### protobuf and gRPC - 5 (Consul: service discovery, load balancing)

- [server](week_07/grpc_lb_server.go)
- [client_lb](week_07/grpc_lb_client_lb.go)

Микросервисы запускаются и падают, разные ноды, хосты, адреса.
Клиентам надо иметь возможность получать информацию о доступных (активных) сервисах -- discovery.

На примере HashiCorp [Consul](https://www.consul.io/)

У него (автора) в докере крутится локальный консул.
Рассмотрим, как в консуле регистрировать сервис, на примере "сервиса сессий" (см. ранее).

Используется grpc и `consul/api`.
Через пакет `flag` и аргументы командной строки задаются параметры соединений с консул и с нашим сервисом.

После старта нашего сервиса идет подключение к консул и использование API для регистрации.
Через defer сразу цепляется функция выноса сервиса из консул.

Продемонстрировал как: запустив два экземпляра сервиса-сессий, посмотреть в консуле их регистрационные записи.

Демонстрация кода клиента с балансировкой нагрузки.
Клиент получает из консул записи доступных (здоровых) сервисов и раскидывает нагрузку по ним.

В примере не показано, но в проде надо использовать health-check параметры и разные метаданные, для фильтрации "здоровых" сервисов.

Балансировка делается прямо в соединении grpc с нашим сервисом, указанием параметров `grpc.WithBlock(), grpc.WithBalancer(...)`

Хитрость в том, что в соединение передается структура `nameResolver`, которая обновляется по ходу течения времени.
В зависимости от данных в консул, которые мы периодически запрашиваем в отдельной горутине.
Горутина делает polling консула раз в 5 секунд и обновляет резолвер.

В принципе, мы не хотим заниматься вот такой ручной балансировкой.
Мы хотим, чтобы облачный инструментарий сам занимался контролем и раскидыванием нагрузки.
Достаточно того, что мы просто регистрируем наш инстанс сервиса в каталоге.

### Дополнительные темы - 1 (JSON REST API grpc-gateway)

- [session.proto](week_07/gateway_session.proto)
- [gateway](week_07/gateway_gateway.go)

grpc-gateway дает возможность использовать под капотом grpc и protobuf, но выглядеть это будет как RESTful JSON API.
Reverse-proxy.
Как это выглядит на практике.

Спека proto дополнена опциями с указанием REST ендпойнтов.
Кодогенерация создает обвязки go, grpc-gateway, swagger.

Код собственно прокси, использующий grpc-gateway, выступает как клиент с сервису grpc.
Запускает коннект к сервису grpc, запускает HTTP сервер построенный на сгенерированном прокси.

### Дополнительные темы - 2 (swagger)

- [session.swagger.json](week_07/swagger_session.swagger.json) сгенерирован сваггером по proto
- [consumer](week_07/swagger_consumer.go)

Open API Specification (OAS) tools, framework.

Декларация API, кодогенерация, документация, тестирование, ...

JSON файл описания API. `swagger serve ...` для запуска интерактива.

`swagger generate client ...`

Демонстрация использования сгенерированного клиентского кода.
Клиент (REST) ходит в grpc-gateway, который обращается к backend на grpc.

Рекомендовано к использованию в проектах с большим количеством сервисов и API.

## part 2, week 4 (08)

Сервис в работе
[Код, домашки, литература](week_08/materials.zip) https://cloud.mail.ru/public/ksKr/X5b6hiyA1

### Конфигурирование сервиса - 1 (commandline args, cfg file, compile-time)

- [flag](week_08/flag.go)
- [json_config](week_08/json_config.go)
- [ldflags](week_08/ldflags.go)

Пакет `flag` для конфигурирования. Парсинг аргументов командной строки в глобальные переменные.
Можно использовать свой тип данных, для этого реализовать интерфейсный метод `func (x *MyType) Set(input string) error {...}`
и зацепить переменную за пакет `flag` в функции `init`.
До вызова `flag.Parse()` (внутри `main`) в переменных лежат значения по умолчанию.

Другой вариант: создать структуру Config и распаковывать в неё конфиг-файл (json, toml, ...).
Не рекомендует для проектов не помещающихся в один файл. Причина: расползается зависимость от конфига по проекту.
Другой недостаток: нет значений по умолчанию.
Недостатки исправляются заворачиванием конфига в интерфейс.

Можно при сборке бинарника указать через флаги набор значений для внутренних переменных.
Версия программы, бранч GIT, whatever.
`go run -ldflags="-X 'main.Version=$(git rev-parse HEAD)'" ldflags.go`

Вопросы
- Зачем нужна `func init() {...}` в файле? Выполняется до `main`, подробности?
- Как делается dependency injection в Go? Статически, в рантайм?

### Конфигурирование сервиса - 2 (hot-reload config, consul)

- [consul_config](week_08/consul_config.go)

Как в программе освежить конфиг без перезапуска?
hot-reload config, online-conf.
key-value хранилище, как данные конфига, в Consul.
В отдельной горутине крутится логика перечитывания конфига из хранилища.
Конфиг перечитывается только если обновился счетчик `WaitIndex`.

Проблема обновления конфига в середине некоего запроса (бизнес-логика), в котором требуется некая согласованность опций.
На время отработки запроса конфиг менять нельзя?
Для решения проблемы сделан декоратор (мидлварь) запроса, в котором создается локальная копия глобальной мапки конфига.
Эта копия через контекст прокидывается по цепочке обработки.
Мапка это ссылочный тип, мы скопировали ссылку (создали ref) и GC это понимает.
Когда мы обновляем конфиг, мы пересоздаем глобальную мапку, старая ссылка убирается GC как неактуальная, но только после того, как
локальная копия перестанет существовать.
Ещё раз: при обновлении конфига не надо писать данные в существующую мапку! Надо пересоздать мапку!

Как трудно людям жить с мутабельными данными.

N.B. Любое конфигурирование на лету должно рассматриваться в контексте бизнес-логики использования опций конфига.
Необходимо следить за согласованностью, изооляцией и атомарностью (atomicity, consistency, isolation, durability).

### Мониторинг - 1 (expvar, graphite)

- [expvars](week_08/expvars.go)
- [graphite](week_08/graphite.go)

Какие инструменты есть в Go для сбора базовых метрик программы (память, горутины).

Пакет `expvar`. Позволяет зарегать дебаг обработчик в handler веб-страницы.
После чего по урл `/debug/vars` нам доступны некоторые показания.
Мы можем в них добавить свою стату: через создание мапки в пакете или регистрации функции в `expvar.Publish`.

Дергать руками такой урл для просмотра статы -- моветон.
Посмотрим, как использовать сервер статы -- graphite.

В асинхроне крутится `sendStat` процедура.
Она коннектится к графиту, запускает канал таймера, тикер и по тикам:
собирает стату по памяти и горутинам, пишет её в буфер и засылает буфер в графит.
Протокол очень простой, три значения через пробел: `имя_метрики значение метрики таймстемп`.

### Мониторинг - 2 (prometheus)

- [status](week_08/prometheus_status.go)
- [prometheus.yml](week_08/prometheus.yml)
- [metrics](week_08/prometheus_metrics.go)

Как работать с фреймворком prometheus.

На свое приложение навешивается handler `/metrics` => `promhttp.Handler()`.
Этот хендлер выдаёт большую простыню разных метрик, в формате нужном прометею.

Теперь надо настроить прометей, чтобы он ходил на эту страничку.
У прометея есть свой дашборд, но лучше использовать графану.

Ладно, сам сервер (процесс) работает. Как собрать метрики по бизнес-логике?
Используем структуры пакета `prometheus`: `NewSummaryVec`, `NewCounterVec` для сбора количества вызовов своих процедур и времени, затраченного в них.
Заворачиваем процедуры в мидлварь (декораторы), где обновляем метрики.

### Низкоуровневое программирование - 1 (unsafe)

- [unsafe](week_08/unsafe.go)
- [bytetostr](week_08/bytetostr.go)

В.Романов надеется, что этим нам заниматься не придётся.

Пакет `unsafe` -- инструмент компилятора. Уходим из уровня абстракции языка на уровень машины.
Не гарантируется совместимость между версиями Go.
На некоторых облаках запрещено использование unsafe.

Примеры:
Получение адреса в памяти для переменной, размера в байтах.
Преобразование типа 64бит из float64 в int64. Меняем тип у 8 байт. Интерпретация бит в области памяти.

Узнать для полей структуры:
размер, выравнивание, смещение.
Простым изменением порядка полей в структуре мы меняем количество памяти, в которую пакуются поля.
Два булевых флага пакуются в одно слово (8 байт), если они идут подряд. Мы можем в одно слово упаковать до 8 булевых флагов.

Демонстрация устройства слайсов, как оно под капотом.
Преобразование слайса байт в строку без копирования памяти, только созданием нового заголовка.
Строка отличается отсутствием поля capacity в заголовке.

### Низкоуровневое программирование - 2 (c from go)

- [cgo_basic](week_08/cgo_basic.go)
- [main.go](week_08/cgo_main.go)
- [main.c](week_08/cgo_main.c)
- [overhead_test](week_08/cgo_overhead_test.go) [overhead](week_08/cgo_overhead.go)
- [memleak](week_08/cgo_memleak.go)
- [go_sleep](week_08/cgo_go_sleep.go) [cgo_sleep](week_08/cgo_c_sleep.go)

Интеграция кода на Go с кодом на C, вызов сишного кода из Го, cgo.

package `C`.
Это псевдопакет, весь код над строкой с `import "C"` будет скомпилирован GCC (теряется кросс-платформенность/компиляция).
Аргументы и результат вызова сишной функции: надо конвертировать из/в Го.

Учтите, используя через такую связку внешние динамически линкуемые библиотеки, вы теряете преимущества статического бинарника, собираемого Го.

Обратная ситуация, как вызвать Го-шный код из С-шного кода.
Экспортируем Го-шную функцию, используем ее в С-шном коде.
Чтобы избежать двойного объявления С-шных функций, в Го-шном файле мы только декларируем С-шную фунцию, реализация этой функции будет
во внешнем С-шном файле.
Сборка через `go build`.

В процессе вызова фунций из разных рантаймов происходит переключение между рантаймами, оверхед при этом будет какой?
100 наносек на переключение.

В С-шном коде нет GC, надо самому следить за памятью. Например, когда прокидываем строки.

Заметим, в cgo нет асинхронщины "из коробки", все синхронно, в текущем потоке.
Демонстрация того, как Го-шные горутины 100 штук крутятся в 6 потоках.
При этом, С-шные горутины 100 штук потребовали 100 потоков. Ибо С-шный код лочит поток на себя.

Выводы: не надо использовать cgo для большого количества мелких вызовов, хождения по сети.

### Инструменты для статического анализа (go vet, gometalinter)

- [vet_example](week_08/vet_example.go)
- [metalinter_example](week_08/metalinter_example.go)

Какие есть инструменты для поддержания кода в корректном виде, соответствующем стандартам.

`go vet vet_example.go`
`gometalinter metalinter_example.go`

И посмотри на вываливающиеся сообщения.
Полезно прикрутить к CI/CD процессам и не позволять коммитить без проверок.
